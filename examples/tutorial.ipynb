{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figaro's prompt templates uses Jinja 2 behind the scenes. Which means, you can\n",
    "use variables, loops, conditions, within a prompt! Figaro also allows you to\n",
    "chain prompts together in a simple way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt Example\n",
    "\n",
    "This example we send a simple prompt to Vertex AI. We want to get the capital\n",
    "of California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:What is the capital of California?\n",
      "INFO:root:Sacramento is the capital of California.\n",
      "INFO:root:\n",
      "Sacramento is the capital of California.\n"
     ]
    }
   ],
   "source": [
    "# Complete (but simple) Figaro example.\n",
    "import figaro\n",
    "\n",
    "template = \"\"\"\n",
    "What is the capital of {{us_state}}?\n",
    "{% gen vertexai \"capital\" model=\"text-bison\" %}\n",
    "\"\"\"\n",
    "\n",
    "# Create a Figaro chain.\n",
    "chain = figaro(template=template, verbose=True)\n",
    "\n",
    "# Execute the chain with \"California\" as the input.\n",
    "result = chain(us_state=\"California\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```jinja2\n",
    "What is the capital of {{us_state}}?\n",
    "```\n",
    "\n",
    "The variable `{{us_state}}` is replaced with the US state passed in when you\n",
    "run Figaro: `chain(us_state=\"California\")`.\n",
    "\n",
    "```jinja2\n",
    "{% gen vertexai \"capital\" model=\"text-bison\" %}\n",
    "```\n",
    "\n",
    "The following line sends everything above it to Vertex AI. `gen` begins the\n",
    "generative command. `vertexai` tells Figaro what AI to use. \n",
    "\n",
    "Next, `\"capital\"` is the variable where the output will go. It's not used in\n",
    "this example, but you'll see later what you can do with it.\n",
    "\n",
    "Finally, `model=\"text-bison\"` is an argument selects which Vertex AI model \n",
    "to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Chaining Example\n",
    "\n",
    "A prompt chain is when you ask the AI one question then you ask it another \n",
    "question based on the previous answer.\n",
    "\n",
    "Without Figaro you might do something like this:\n",
    "\n",
    "```py\n",
    "prompt1 = \"What is the capital of California?\n",
    "answer1 = predict(prompt1)\n",
    "prompt2 = \"What is \" + answer1 + \"'s population?\n",
    "answer2 = predict(prompt2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:What is the capital of California? Only return the name of the city.\n",
      "INFO:root:The capital of California is Sacramento.\n",
      "INFO:root:What is The capital of California is Sacramento.'s current population? Only return a number.\n",
      "INFO:root:498,352\n",
      "INFO:root:\n",
      "498,352\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "What is the capital of {{us_state}}? Only return the name of the city.\n",
    "{% gen vertexai \"capital\" model=\"text-bison\" %}\n",
    "\n",
    "What is {{capital}}'s current population? Only return a number.\n",
    "{% gen vertexai \"population\" model=\"text-bison\" %}\n",
    "\"\"\"\n",
    "\n",
    "# Create a Figaro chain.\n",
    "chain = figaro(template=template, verbose=True)\n",
    "\n",
    "# Execute the chain with \"California\" as the input.\n",
    "result = chain(us_state=\"California\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see we have two prompts. The first asks what is the capital of\n",
    "California. The second prompt asks for the capital's current population but we\n",
    "specifically replaced `capital` with the answer from the first question.\n",
    "\n",
    "Under the hood Figaro is taking the input of the first prompt and it's output,\n",
    "combining it with the second prompt to get the second output.\n",
    "\n",
    "First prompt:\n",
    "```\n",
    "What is the capital of California? Only return the name of the city.\n",
    "```\n",
    "\n",
    "First answer:\n",
    "```\n",
    "Sacramento\n",
    "```\n",
    "\n",
    "Second prompt:\n",
    "```\n",
    "What is the capital of California? Only return the name of the city.\n",
    "Sacramento\n",
    "What is Sacramento's current population? Only return a number.\n",
    "```\n",
    "\n",
    "Second answer:\n",
    "```\n",
    "493,784\n",
    "```\n",
    "\n",
    "Finally, `chain()` will return the output from the last varaible `population`.\n",
    "\n",
    "Why use Figaro? Traditionally you might do something like this:\n",
    "\n",
    "```py\n",
    "def call_vertex_ai(prompt):\n",
    "  model = TextGenerationModel.from_pretrained(\"text-bison\")\n",
    "  parameters = { 'temperature': 0.2, \"max_tokens\": 1024 }\n",
    "  return model.predict(prompt, **parameters)\n",
    "\n",
    "state = \"California\"\n",
    "prompt1 = \"What is the capital of \" + state + \"?\"\n",
    "answer1 = call_vertex_ai(prompt1)\n",
    "prompt2 = \"What is \" + answer1 + 's current population?\"\n",
    "answer2 = call_vertex_ai(prompt2)\n",
    "print(answer2)\n",
    "```\n",
    "\n",
    "This might be fine for this example but concatting strings, loops, and branch\n",
    "conditions start making the code harder to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
